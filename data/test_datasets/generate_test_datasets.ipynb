{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Synthetic Dataset Generator for Quality Rater App\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Dataset 1: Customer Banking Data\n",
      "âœ… Saved: banking_real.csv (2000 rows, 9 columns)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\data_rater\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:168: FutureWarning:\n",
      "\n",
      "The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
      "\n",
      "d:\\Documents\\data_rater\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:134: UserWarning:\n",
      "\n",
      "We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: banking_synthetic.csv (GaussianCopula)\n",
      "\n",
      "ðŸ›’ Dataset 2: E-commerce Transactions\n",
      "âœ… Saved: ecommerce_real.csv (5000 rows, 10 columns)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\data_rater\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:168: FutureWarning:\n",
      "\n",
      "The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
      "\n",
      "d:\\Documents\\data_rater\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:134: UserWarning:\n",
      "\n",
      "We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: ecommerce_synthetic.csv (GaussianCopula)\n",
      "\n",
      "ðŸ¥ Dataset 3: Medical Patient Records\n",
      "âœ… Saved: medical_real.csv (1500 rows, 10 columns)\n",
      "   âš ï¸  Note: Contains 233 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\data_rater\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:168: FutureWarning:\n",
      "\n",
      "The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
      "\n",
      "d:\\Documents\\data_rater\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:134: UserWarning:\n",
      "\n",
      "We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: medical_synthetic.csv (GaussianCopula)\n",
      "\n",
      "ðŸŽ¯ Dataset 4: Simple Test Case\n",
      "âœ… Saved: simple_real.csv (1000 rows, 5 columns)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\data_rater\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:168: FutureWarning:\n",
      "\n",
      "The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
      "\n",
      "d:\\Documents\\data_rater\\.venv\\Lib\\site-packages\\sdv\\single_table\\base.py:134: UserWarning:\n",
      "\n",
      "We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: simple_synthetic.csv (GaussianCopula)\n",
      "\n",
      "============================================================\n",
      "âœ¨ Dataset Generation Complete!\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Generated Test Datasets:\n",
      "   1. Banking Data:     banking_real.csv + banking_synthetic.csv\n",
      "   2. E-commerce:       ecommerce_real.csv + ecommerce_synthetic.csv\n",
      "   3. Medical Records:  medical_real.csv + medical_synthetic.csv\n",
      "   4. Simple Test:      simple_real.csv + simple_synthetic.csv\n",
      "\n",
      "ðŸ’¡ Usage:\n",
      "   - Upload any *_real.csv as 'Original dataset'\n",
      "   - Upload matching *_synthetic.csv as 'Synthetic dataset'\n",
      "   - Compare quality scores across different dataset types\n",
      "\n",
      "ðŸ“Š Expected Quality Scores:\n",
      "   - Simple Test:       0.85-0.95 (should score high)\n",
      "   - Banking Data:      0.70-0.85 (good quality)\n",
      "   - E-commerce:        0.65-0.80 (moderate complexity)\n",
      "   - Medical Records:   0.60-0.75 (handles missing data)\n",
      "\n",
      "ðŸŽ¯ All datasets saved to current directory\n"
     ]
    }
   ],
   "source": [
    "# Synthetic Dataset Generator for Testing\n",
    "# This notebook creates real and synthetic dataset pairs for testing the quality rater app\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer, TVAESynthesizer\n",
    "import os\n",
    "\n",
    "print(\"ðŸŽ¯ Synthetic Dataset Generator for Quality Rater App\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# Dataset 1: Customer Banking Data (Medium Complexity)\n",
    "# ============================================================================\n",
    "print(\"\\nðŸ“Š Dataset 1: Customer Banking Data\")\n",
    "\n",
    "np.random.seed(42)\n",
    "n_customers = 2000\n",
    "\n",
    "# Generate realistic customer data with correlations\n",
    "age = np.random.normal(45, 15, n_customers).clip(18, 85)\n",
    "income = 20000 + (age - 18) * 1200 + np.random.normal(0, 15000, n_customers)\n",
    "income = income.clip(20000, 300000)\n",
    "\n",
    "credit_score = 300 + (income / 1000) * 1.5 + np.random.normal(0, 50, n_customers)\n",
    "credit_score = credit_score.clip(300, 850)\n",
    "\n",
    "# Premium customers have higher income and credit scores\n",
    "is_premium = (income > 75000) & (credit_score > 700)\n",
    "is_premium = is_premium | (np.random.random(n_customers) < 0.1)  # 10% random premium\n",
    "\n",
    "account_balance = np.where(is_premium, \n",
    "                           np.random.exponential(15000, n_customers),\n",
    "                           np.random.exponential(3000, n_customers))\n",
    "\n",
    "num_transactions = np.random.poisson(20 + (is_premium * 15), n_customers)\n",
    "\n",
    "regions = np.random.choice(['North', 'South', 'East', 'West'], n_customers)\n",
    "segments = np.where(is_premium, \n",
    "                    np.random.choice(['Gold', 'Platinum'], n_customers),\n",
    "                    np.random.choice(['Bronze', 'Silver'], n_customers))\n",
    "\n",
    "banking_data = pd.DataFrame({\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'age': age.astype(int),\n",
    "    'income': income.round(2),\n",
    "    'credit_score': credit_score.round(0).astype(int),\n",
    "    'account_balance': account_balance.round(2),\n",
    "    'num_transactions': num_transactions,\n",
    "    'is_premium': is_premium.astype(int),\n",
    "    'region': regions,\n",
    "    'customer_segment': segments\n",
    "})\n",
    "\n",
    "# Save real dataset\n",
    "banking_data.to_csv('banking_real.csv', index=False)\n",
    "print(f\"âœ… Saved: banking_real.csv ({len(banking_data)} rows, {len(banking_data.columns)} columns)\")\n",
    "\n",
    "# Generate synthetic version using GaussianCopula\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(banking_data)\n",
    "\n",
    "synthesizer = GaussianCopulaSynthesizer(metadata)\n",
    "synthesizer.fit(banking_data)\n",
    "banking_synthetic = synthesizer.sample(num_rows=len(banking_data))\n",
    "banking_synthetic.to_csv('banking_synthetic.csv', index=False)\n",
    "print(f\"âœ… Saved: banking_synthetic.csv (GaussianCopula)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Dataset 2: E-commerce Transactions (High Complexity)\n",
    "# ============================================================================\n",
    "print(\"\\nðŸ›’ Dataset 2: E-commerce Transactions\")\n",
    "\n",
    "np.random.seed(123)\n",
    "n_transactions = 5000\n",
    "\n",
    "# Generate transaction data with temporal patterns\n",
    "days = np.random.randint(1, 366, n_transactions)\n",
    "is_weekend = np.isin(days % 7, [0, 6])\n",
    "is_holiday = np.isin(days, [1, 365, 180, 270])  # Major holidays\n",
    "\n",
    "# Higher transaction amounts on weekends/holidays\n",
    "base_amount = np.random.gamma(2, 30, n_transactions)\n",
    "amount = np.where(is_weekend | is_holiday, base_amount * 1.5, base_amount)\n",
    "amount = amount.clip(5, 500)\n",
    "\n",
    "# Customer types affect behavior\n",
    "customer_type = np.random.choice(['New', 'Regular', 'VIP'], n_transactions, p=[0.3, 0.5, 0.2])\n",
    "discount_pct = np.where(customer_type == 'VIP', \n",
    "                        np.random.uniform(10, 30, n_transactions),\n",
    "                        np.where(customer_type == 'Regular',\n",
    "                                np.random.uniform(0, 15, n_transactions),\n",
    "                                np.random.uniform(0, 5, n_transactions)))\n",
    "\n",
    "items_purchased = np.where(customer_type == 'VIP',\n",
    "                           np.random.poisson(5, n_transactions),\n",
    "                           np.random.poisson(2, n_transactions)) + 1\n",
    "\n",
    "payment_method = np.where(amount > 100,\n",
    "                         np.random.choice(['Credit', 'Debit', 'PayPal'], n_transactions, p=[0.6, 0.2, 0.2]),\n",
    "                         np.random.choice(['Credit', 'Debit', 'PayPal'], n_transactions, p=[0.3, 0.5, 0.2]))\n",
    "\n",
    "categories = np.random.choice(['Electronics', 'Clothing', 'Home', 'Sports', 'Books'], n_transactions)\n",
    "\n",
    "ecommerce_data = pd.DataFrame({\n",
    "    'transaction_id': range(1, n_transactions + 1),\n",
    "    'day_of_year': days,\n",
    "    'amount': amount.round(2),\n",
    "    'discount_pct': discount_pct.round(1),\n",
    "    'items_purchased': items_purchased,\n",
    "    'customer_type': customer_type,\n",
    "    'payment_method': payment_method,\n",
    "    'category': categories,\n",
    "    'is_weekend': is_weekend.astype(int),\n",
    "    'is_holiday': is_holiday.astype(int)\n",
    "})\n",
    "\n",
    "# Save real dataset\n",
    "ecommerce_data.to_csv('ecommerce_real.csv', index=False)\n",
    "print(f\"âœ… Saved: ecommerce_real.csv ({len(ecommerce_data)} rows, {len(ecommerce_data.columns)} columns)\")\n",
    "\n",
    "# Generate synthetic version\n",
    "metadata2 = SingleTableMetadata()\n",
    "metadata2.detect_from_dataframe(ecommerce_data)\n",
    "\n",
    "synthesizer2 = GaussianCopulaSynthesizer(metadata2)\n",
    "synthesizer2.fit(ecommerce_data)\n",
    "ecommerce_synthetic = synthesizer2.sample(num_rows=len(ecommerce_data))\n",
    "ecommerce_synthetic.to_csv('ecommerce_synthetic.csv', index=False)\n",
    "print(f\"âœ… Saved: ecommerce_synthetic.csv (GaussianCopula)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Dataset 3: Medical Patient Records (Complex with Missing Data)\n",
    "# ============================================================================\n",
    "print(\"\\nðŸ¥ Dataset 3: Medical Patient Records\")\n",
    "\n",
    "np.random.seed(789)\n",
    "n_patients = 1500\n",
    "\n",
    "patient_age = np.random.normal(55, 20, n_patients).clip(18, 95).astype(int)\n",
    "gender = np.random.choice(['M', 'F'], n_patients)\n",
    "\n",
    "# Correlated health metrics\n",
    "bmi = np.random.normal(27, 5, n_patients).clip(15, 50)\n",
    "blood_pressure_sys = 90 + (bmi - 20) * 2 + np.random.normal(0, 15, n_patients)\n",
    "blood_pressure_sys = blood_pressure_sys.clip(80, 200)\n",
    "\n",
    "cholesterol = 150 + (bmi - 20) * 5 + np.random.normal(0, 30, n_patients)\n",
    "cholesterol = cholesterol.clip(100, 400)\n",
    "\n",
    "# Diagnosis based on risk factors\n",
    "high_risk = (bmi > 30) | (blood_pressure_sys > 140) | (cholesterol > 240)\n",
    "diagnosis = np.where(high_risk,\n",
    "                    np.random.choice(['Hypertension', 'Diabetes', 'Heart Disease'], n_patients),\n",
    "                    np.random.choice(['Healthy', 'Mild Risk'], n_patients, p=[0.7, 0.3]))\n",
    "\n",
    "num_visits = np.where(high_risk, \n",
    "                     np.random.poisson(8, n_patients),\n",
    "                     np.random.poisson(2, n_patients)) + 1\n",
    "\n",
    "medications = np.where(high_risk,\n",
    "                      np.random.randint(1, 5, n_patients),\n",
    "                      np.random.randint(0, 2, n_patients))\n",
    "\n",
    "# Add some missing values (realistic for medical data)\n",
    "glucose = np.random.normal(100, 25, n_patients)\n",
    "glucose = np.where(np.random.random(n_patients) < 0.15, np.nan, glucose)  # 15% missing\n",
    "\n",
    "medical_data = pd.DataFrame({\n",
    "    'patient_id': range(1, n_patients + 1),\n",
    "    'age': patient_age,\n",
    "    'gender': gender,\n",
    "    'bmi': bmi.round(1),\n",
    "    'blood_pressure_systolic': blood_pressure_sys.round(0),\n",
    "    'cholesterol': cholesterol.round(0),\n",
    "    'glucose': glucose,\n",
    "    'diagnosis': diagnosis,\n",
    "    'num_visits': num_visits,\n",
    "    'medications': medications\n",
    "})\n",
    "\n",
    "# Save real dataset\n",
    "medical_data.to_csv('medical_real.csv', index=False)\n",
    "print(f\"âœ… Saved: medical_real.csv ({len(medical_data)} rows, {len(medical_data.columns)} columns)\")\n",
    "print(f\"   âš ï¸  Note: Contains {medical_data['glucose'].isna().sum()} missing values\")\n",
    "\n",
    "# Generate synthetic version\n",
    "metadata3 = SingleTableMetadata()\n",
    "metadata3.detect_from_dataframe(medical_data)\n",
    "\n",
    "synthesizer3 = GaussianCopulaSynthesizer(metadata3)\n",
    "synthesizer3.fit(medical_data)\n",
    "medical_synthetic = synthesizer3.sample(num_rows=len(medical_data))\n",
    "medical_synthetic.to_csv('medical_synthetic.csv', index=False)\n",
    "print(f\"âœ… Saved: medical_synthetic.csv (GaussianCopula)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Dataset 4: Simple Test Case (Low Complexity - Should Score High)\n",
    "# ============================================================================\n",
    "print(\"\\nðŸŽ¯ Dataset 4: Simple Test Case\")\n",
    "\n",
    "np.random.seed(999)\n",
    "n_simple = 1000\n",
    "\n",
    "simple_data = pd.DataFrame({\n",
    "    'id': range(1, n_simple + 1),\n",
    "    'value_a': np.random.normal(100, 15, n_simple),\n",
    "    'value_b': np.random.exponential(50, n_simple),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], n_simple),\n",
    "    'flag': np.random.choice([0, 1], n_simple, p=[0.7, 0.3])\n",
    "})\n",
    "\n",
    "simple_data.to_csv('simple_real.csv', index=False)\n",
    "print(f\"âœ… Saved: simple_real.csv ({len(simple_data)} rows, {len(simple_data.columns)} columns)\")\n",
    "\n",
    "# Generate high-quality synthetic\n",
    "metadata4 = SingleTableMetadata()\n",
    "metadata4.detect_from_dataframe(simple_data)\n",
    "\n",
    "synthesizer4 = GaussianCopulaSynthesizer(metadata4)\n",
    "synthesizer4.fit(simple_data)\n",
    "simple_synthetic = synthesizer4.sample(num_rows=len(simple_data))\n",
    "simple_synthetic.to_csv('simple_synthetic.csv', index=False)\n",
    "print(f\"âœ… Saved: simple_synthetic.csv (GaussianCopula)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ¨ Dataset Generation Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nðŸ“ Generated Test Datasets:\")\n",
    "print(\"   1. Banking Data:     banking_real.csv + banking_synthetic.csv\")\n",
    "print(\"   2. E-commerce:       ecommerce_real.csv + ecommerce_synthetic.csv\")\n",
    "print(\"   3. Medical Records:  medical_real.csv + medical_synthetic.csv\")\n",
    "print(\"   4. Simple Test:      simple_real.csv + simple_synthetic.csv\")\n",
    "print(\"\\nðŸ’¡ Usage:\")\n",
    "print(\"   - Upload any *_real.csv as 'Original dataset'\")\n",
    "print(\"   - Upload matching *_synthetic.csv as 'Synthetic dataset'\")\n",
    "print(\"   - Compare quality scores across different dataset types\")\n",
    "print(\"\\nðŸ“Š Expected Quality Scores:\")\n",
    "print(\"   - Simple Test:       0.85-0.95 (should score high)\")\n",
    "print(\"   - Banking Data:      0.70-0.85 (good quality)\")\n",
    "print(\"   - E-commerce:        0.65-0.80 (moderate complexity)\")\n",
    "print(\"   - Medical Records:   0.60-0.75 (handles missing data)\")\n",
    "print(\"\\nðŸŽ¯ All datasets saved to current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
